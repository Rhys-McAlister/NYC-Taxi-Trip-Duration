{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep:\n",
    "    def __init__(self, file):\n",
    "        import pandas as pd\n",
    "        data = pd.read_csv(file)\n",
    "        self.data = data\n",
    "\n",
    "    def change_to_datetime(self):\n",
    "        self.data.pickup_datetime = pd.to_datetime(self.data.pickup_datetime)\n",
    "        try:\n",
    "            self.data.dropoff_datetime = pd.to_datetime(self.data.dropoff_datetime)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    # Feature is already created in kaggle dataset\n",
    "\n",
    "    # def target_creation(self):\n",
    "    #     self.data['trip_duration'] = self.data['dropoff_datetime'] - self.data['pickup_datetime']\n",
    "    #     self.data['trip_duration'] = self.data['trip_duration'].dt.total_seconds()\n",
    "        \n",
    "    def dup_and_miss(self):\n",
    "        print(f\"Number of duplicated rows: {self.data.duplicated().sum()}\")\n",
    "        print(f\"Number of NA rows: {self.data.isna().sum().sum()}\")\n",
    "\n",
    "    def outlier_removal(self):\n",
    "        self.data = self.data[(self.data.trip_duration < 5600)]\n",
    "        self.data = self.data[(self.data.trip_duration > 0)]\n",
    "        self.data = self.data[(self.data.passenger_count > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepTest:\n",
    "    def __init__(self, file):\n",
    "        import pandas as pd\n",
    "        data = pd.read_csv(file)\n",
    "        self.data = data\n",
    "\n",
    "    def change_to_datetime(self):\n",
    "        self.data.pickup_datetime = pd.to_datetime(self.data.pickup_datetime)\n",
    "        # try:\n",
    "        #     self.data.dropoff_datetime = pd.to_datetime(self.data.dropoff_datetime)\n",
    "        # except AttributeError:\n",
    "        #     pass\n",
    "    # Feature is already created in kaggle dataset\n",
    "\n",
    "    # def target_creation(self):\n",
    "    #     self.data['trip_duration'] = self.data['dropoff_datetime'] - self.data['pickup_datetime']\n",
    "    #     self.data['trip_duration'] = self.data['trip_duration'].dt.total_seconds()\n",
    "        \n",
    "    def dup_and_miss(self):\n",
    "        print(f\"Number of duplicated rows: {self.data.duplicated().sum()}\")\n",
    "        print(f\"Number of NA rows: {self.data.isna().sum().sum()}\")\n",
    "\n",
    "    # def outlier_removal(self):\n",
    "    #     # self.data = self.data[(self.data.trip_duration < 5600)]\n",
    "    #     # self.data = self.data[(self.data.trip_duration > 0)]\n",
    "    #     self.data = self.data[(self.data.passenger_count > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n",
      "Number of NA rows: 0\n"
     ]
    }
   ],
   "source": [
    "prep = DataPrep('train.csv')\n",
    "prep.change_to_datetime()\n",
    "prep.dup_and_miss()\n",
    "prep.outlier_removal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n",
      "Number of NA rows: 0\n"
     ]
    }
   ],
   "source": [
    "test_prep = DataPrepTest('test.csv')\n",
    "test_prep.change_to_datetime()\n",
    "test_prep.dup_and_miss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "\n",
    "    def __init__(self, prep):\n",
    "        self.data = prep.data\n",
    "        \n",
    "    def one_hot(self):\n",
    "        self.data = pd.concat([self.data, pd.get_dummies(self.data['store_and_fwd_flag'])], axis=1)\n",
    "        self.data = pd.concat([self.data, pd.get_dummies(self.data['vendor_id'])], axis=1)\n",
    "        self.data.drop(['store_and_fwd_flag'], axis=1, inplace=True)\n",
    "        self.data.drop(['vendor_id'], axis=1, inplace=True)\n",
    "\n",
    "    def date_features(self):\n",
    "        self.data['month'] = self.data.pickup_datetime.dt.month\n",
    "        self.data['day'] = self.data.pickup_datetime.dt.day\n",
    "        self.data['hour'] = self.data.pickup_datetime.dt.hour\n",
    "        self.data['minute'] = self.data.pickup_datetime.dt.minute\n",
    "        self.data['day_of_week'] = self.data.pickup_datetime.dt.dayofweek\n",
    "        # self.data['week'] = self.data.pickup_datetime.dt.isocalendar().week\n",
    "        self.data['weekday'] = self.data.pickup_datetime.dt.weekday\n",
    "        return self.data.info()\n",
    "\n",
    "    def drop_cols(self):\n",
    "        try:\n",
    "            self.data = self.data.drop(['dropoff_datetime'], axis=1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        self.data = self.data.drop(['pickup_datetime'], axis=1)\n",
    "        # self.data = self.data.drop(['id'], axis=1)\n",
    "\n",
    "        # # These cols don't exist in the kaggle dataset\n",
    "        # # self.data = self.data.drop(['DOLocationID'], axis=1)\n",
    "        # # self.data = self.data.drop(['PULocationID'], axis=1)\n",
    "        # # self.data = self.data.drop(['airport_fee'], axis=1)\n",
    "        # # self.data = self.data.drop(['RatecodeID'], axis=1)\n",
    "        # # self.data = self.data.drop(['congestion_surcharge'], axis=1)\n",
    "        # self.data = self.data.drop(['passenger_count'], axis=1)\n",
    "\n",
    "    def cols_to_str(self):\n",
    "        self.data.columns = self.data.columns.astype(str)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe = FeatureEngineering(test_prep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe.one_hot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 625134 entries, 0 to 625133\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   id                 625134 non-null  object        \n",
      " 1   pickup_datetime    625134 non-null  datetime64[ns]\n",
      " 2   passenger_count    625134 non-null  int64         \n",
      " 3   pickup_longitude   625134 non-null  float64       \n",
      " 4   pickup_latitude    625134 non-null  float64       \n",
      " 5   dropoff_longitude  625134 non-null  float64       \n",
      " 6   dropoff_latitude   625134 non-null  float64       \n",
      " 7   N                  625134 non-null  uint8         \n",
      " 8   Y                  625134 non-null  uint8         \n",
      " 9   1                  625134 non-null  uint8         \n",
      " 10  2                  625134 non-null  uint8         \n",
      " 11  month              625134 non-null  int64         \n",
      " 12  day                625134 non-null  int64         \n",
      " 13  hour               625134 non-null  int64         \n",
      " 14  minute             625134 non-null  int64         \n",
      " 15  day_of_week        625134 non-null  int64         \n",
      " 16  weekday            625134 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(7), object(1), uint8(4)\n",
      "memory usage: 64.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_fe.date_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe.drop_cols()\n",
    "test_fe.cols_to_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1455721 entries, 0 to 1458643\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count    Dtype         \n",
      "---  ------             --------------    -----         \n",
      " 0   id                 1455721 non-null  object        \n",
      " 1   pickup_datetime    1455721 non-null  datetime64[ns]\n",
      " 2   dropoff_datetime   1455721 non-null  datetime64[ns]\n",
      " 3   passenger_count    1455721 non-null  int64         \n",
      " 4   pickup_longitude   1455721 non-null  float64       \n",
      " 5   pickup_latitude    1455721 non-null  float64       \n",
      " 6   dropoff_longitude  1455721 non-null  float64       \n",
      " 7   dropoff_latitude   1455721 non-null  float64       \n",
      " 8   trip_duration      1455721 non-null  int64         \n",
      " 9   N                  1455721 non-null  uint8         \n",
      " 10  Y                  1455721 non-null  uint8         \n",
      " 11  1                  1455721 non-null  uint8         \n",
      " 12  2                  1455721 non-null  uint8         \n",
      " 13  month              1455721 non-null  int64         \n",
      " 14  day                1455721 non-null  int64         \n",
      " 15  hour               1455721 non-null  int64         \n",
      " 16  minute             1455721 non-null  int64         \n",
      " 17  day_of_week        1455721 non-null  int64         \n",
      " 18  weekday            1455721 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(8), object(1), uint8(4)\n",
      "memory usage: 183.3+ MB\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineering(prep)\n",
    "fe.one_hot()\n",
    "fe.date_features()\n",
    "fe.drop_cols()\n",
    "fe.cols_to_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, fe):\n",
    "        self.data = fe.data\n",
    "\n",
    "    def train_test_split(self):\n",
    "        y = self.data['trip_duration']\n",
    "        X = self.data.drop(['trip_duration', 'id'], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def random_forest(self):\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        print(f\"Random Forest RMSE: {mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "\n",
    "    def light_gbm(self):\n",
    "        from sklearn.metrics import mean_squared_error as MSE\n",
    "        import lightgbm as lgb\n",
    "        from lightgbm import LGBMRegressor\n",
    "        import numpy as np\n",
    "        lgbm = lgb.LGBMRegressor()\n",
    "        lgbm.fit(X_train, y_train)\n",
    "        print(lgbm.score(X_train, y_train), lgbm.score(X_test, y_test))\n",
    "        print(f\"MSE: {np.sqrt(MSE(y_test, lgbm.predict(X_test)))}\")\n",
    "       \n",
    "\n",
    "    def light_preds(self):\n",
    "        import numpy as np\n",
    "        import lightgbm as lgb\n",
    "        from lightgbm import LGBMRegressor\n",
    "        lgbm = lgb.LGBMRegressor()\n",
    "        lgbm.fit(X_train, y_train)\n",
    "        test_x_data = test_fe.data.drop(['id'], axis = 1)\n",
    "        preds = lgbm.predict(test_x_data)\n",
    "        print(preds.shape)\n",
    "        return preds\n",
    "\n",
    "    def lrrr(self):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        print(lr.score(X_train, y_train), lr.score(X_test, y_test))\n",
    "        print(f\"Linear Regression RMSE: {mean_squared_error(y_test, lr.predict(X_test), squared=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7534109573529395 0.755279669413204\n",
      "MSE: 318.92042732078653\n"
     ]
    }
   ],
   "source": [
    "model = Model(fe)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model.train_test_split()\n",
    "model.light_gbm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# show which version of scikit-learn is installed\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09763574050983537 0.07058539167858668\n",
      "Linear Regression RMSE: 621.515636199946\n"
     ]
    }
   ],
   "source": [
    "model.lrrr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625134,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 731.19844802,  595.60212724,  545.68000925, ..., 1358.77518918,\n",
       "       1780.41291636, 1003.33188942])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.light_preds()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3004672</td>\n",
       "      <td>731.198448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3505355</td>\n",
       "      <td>595.602127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id1217141</td>\n",
       "      <td>545.680009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2150126</td>\n",
       "      <td>999.437783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id1598245</td>\n",
       "      <td>469.483720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  trip_duration\n",
       "0  id3004672     731.198448\n",
       "1  id3505355     595.602127\n",
       "2  id1217141     545.680009\n",
       "3  id2150126     999.437783\n",
       "4  id1598245     469.483720"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'id': test_fe.data.id, 'trip_duration': preds})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilePathOrBuffer' from 'pandas._typing' (c:\\Users\\rhys-\\anaconda3\\lib\\site-packages\\pandas\\_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sub\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39msub.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\rhys-\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtake\u001b[39m(\n\u001b[0;32m   3522\u001b[0m     \u001b[39mself\u001b[39m: FrameOrSeries, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, is_copy: bool_t \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   3523\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeries:\n\u001b[0;32m   3524\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3525\u001b[0m \u001b[39m    Return the elements in the given *positional* indices along an axis.\u001b[39;00m\n\u001b[0;32m   3526\u001b[0m \n\u001b[0;32m   3527\u001b[0m \u001b[39m    This means that we are not indexing according to actual values in\u001b[39;00m\n\u001b[0;32m   3528\u001b[0m \u001b[39m    the index attribute of the object. We are indexing according to the\u001b[39;00m\n\u001b[0;32m   3529\u001b[0m \u001b[39m    actual position of the element in the object.\u001b[39;00m\n\u001b[0;32m   3530\u001b[0m \n\u001b[0;32m   3531\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   3532\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[0;32m   3533\u001b[0m \u001b[39m    indices : array-like\u001b[39;00m\n\u001b[0;32m   3534\u001b[0m \u001b[39m        An array of ints indicating which positions to take.\u001b[39;00m\n\u001b[0;32m   3535\u001b[0m \u001b[39m    axis : {0 or 'index', 1 or 'columns', None}, default 0\u001b[39;00m\n\u001b[0;32m   3536\u001b[0m \u001b[39m        The axis on which to select elements. ``0`` means that we are\u001b[39;00m\n\u001b[0;32m   3537\u001b[0m \u001b[39m        selecting rows, ``1`` means that we are selecting columns.\u001b[39;00m\n\u001b[0;32m   3538\u001b[0m \u001b[39m    is_copy : bool\u001b[39;00m\n\u001b[0;32m   3539\u001b[0m \u001b[39m        Before pandas 1.0, ``is_copy=False`` can be specified to ensure\u001b[39;00m\n\u001b[0;32m   3540\u001b[0m \u001b[39m        that the return value is an actual copy. Starting with pandas 1.0,\u001b[39;00m\n\u001b[0;32m   3541\u001b[0m \u001b[39m        ``take`` always returns a copy, and the keyword is therefore\u001b[39;00m\n\u001b[0;32m   3542\u001b[0m \u001b[39m        deprecated.\u001b[39;00m\n\u001b[0;32m   3543\u001b[0m \n\u001b[0;32m   3544\u001b[0m \u001b[39m        .. deprecated:: 1.0.0\u001b[39;00m\n\u001b[0;32m   3545\u001b[0m \u001b[39m    **kwargs\u001b[39;00m\n\u001b[0;32m   3546\u001b[0m \u001b[39m        For compatibility with :meth:`numpy.take`. Has no effect on the\u001b[39;00m\n\u001b[0;32m   3547\u001b[0m \u001b[39m        output.\u001b[39;00m\n\u001b[0;32m   3548\u001b[0m \n\u001b[0;32m   3549\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[0;32m   3550\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m-> 3551\u001b[0m \u001b[39m    taken : same type as caller\u001b[39;00m\n\u001b[0;32m   3552\u001b[0m \u001b[39m        An array-like containing the elements taken from the object.\u001b[39;00m\n\u001b[0;32m   3553\u001b[0m \n\u001b[0;32m   3554\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[0;32m   3555\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[0;32m   3556\u001b[0m \u001b[39m    DataFrame.loc : Select a subset of a DataFrame by labels.\u001b[39;00m\n\u001b[0;32m   3557\u001b[0m \u001b[39m    DataFrame.iloc : Select a subset of a DataFrame by positions.\u001b[39;00m\n\u001b[0;32m   3558\u001b[0m \u001b[39m    numpy.take : Take elements from an array along an axis.\u001b[39;00m\n\u001b[0;32m   3559\u001b[0m \n\u001b[0;32m   3560\u001b[0m \u001b[39m    Examples\u001b[39;00m\n\u001b[0;32m   3561\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[0;32m   3562\u001b[0m \u001b[39m    >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\u001b[39;00m\n\u001b[0;32m   3563\u001b[0m \u001b[39m    ...                    ('parrot', 'bird', 24.0),\u001b[39;00m\n\u001b[0;32m   3564\u001b[0m \u001b[39m    ...                    ('lion', 'mammal', 80.5),\u001b[39;00m\n\u001b[0;32m   3565\u001b[0m \u001b[39m    ...                    ('monkey', 'mammal', np.nan)],\u001b[39;00m\n\u001b[0;32m   3566\u001b[0m \u001b[39m    ...                   columns=['name', 'class', 'max_speed'],\u001b[39;00m\n\u001b[0;32m   3567\u001b[0m \u001b[39m    ...                   index=[0, 2, 3, 1])\u001b[39;00m\n\u001b[0;32m   3568\u001b[0m \u001b[39m    >>> df\u001b[39;00m\n\u001b[0;32m   3569\u001b[0m \u001b[39m         name   class  max_speed\u001b[39;00m\n\u001b[0;32m   3570\u001b[0m \u001b[39m    0  falcon    bird      389.0\u001b[39;00m\n\u001b[0;32m   3571\u001b[0m \u001b[39m    2  parrot    bird       24.0\u001b[39;00m\n\u001b[0;32m   3572\u001b[0m \u001b[39m    3    lion  mammal       80.5\u001b[39;00m\n\u001b[0;32m   3573\u001b[0m \u001b[39m    1  monkey  mammal        NaN\u001b[39;00m\n\u001b[0;32m   3574\u001b[0m \n\u001b[0;32m   3575\u001b[0m \u001b[39m    Take elements at positions 0 and 3 along the axis 0 (default).\u001b[39;00m\n\u001b[0;32m   3576\u001b[0m \n\u001b[0;32m   3577\u001b[0m \u001b[39m    Note how the actual indices selected (0 and 1) do not correspond to\u001b[39;00m\n\u001b[0;32m   3578\u001b[0m \u001b[39m    our selected indices 0 and 3. That's because we are selecting the 0th\u001b[39;00m\n\u001b[0;32m   3579\u001b[0m \u001b[39m    and 3rd rows, not rows whose indices equal 0 and 3.\u001b[39;00m\n\u001b[0;32m   3580\u001b[0m \n\u001b[0;32m   3581\u001b[0m \u001b[39m    >>> df.take([0, 3])\u001b[39;00m\n\u001b[0;32m   3582\u001b[0m \u001b[39m         name   class  max_speed\u001b[39;00m\n\u001b[0;32m   3583\u001b[0m \u001b[39m    0  falcon    bird      389.0\u001b[39;00m\n\u001b[0;32m   3584\u001b[0m \u001b[39m    1  monkey  mammal        NaN\u001b[39;00m\n\u001b[0;32m   3585\u001b[0m \n\u001b[0;32m   3586\u001b[0m \u001b[39m    Take elements at indices 1 and 2 along the axis 1 (column selection).\u001b[39;00m\n\u001b[0;32m   3587\u001b[0m \n\u001b[0;32m   3588\u001b[0m \u001b[39m    >>> df.take([1, 2], axis=1)\u001b[39;00m\n\u001b[0;32m   3589\u001b[0m \u001b[39m        class  max_speed\u001b[39;00m\n\u001b[0;32m   3590\u001b[0m \u001b[39m    0    bird      389.0\u001b[39;00m\n\u001b[0;32m   3591\u001b[0m \u001b[39m    2    bird       24.0\u001b[39;00m\n\u001b[0;32m   3592\u001b[0m \u001b[39m    3  mammal       80.5\u001b[39;00m\n\u001b[0;32m   3593\u001b[0m \u001b[39m    1  mammal        NaN\u001b[39;00m\n\u001b[0;32m   3594\u001b[0m \n\u001b[0;32m   3595\u001b[0m \u001b[39m    We may take elements using negative integers for positive indices,\u001b[39;00m\n\u001b[0;32m   3596\u001b[0m \u001b[39m    starting from the end of the object, just like with Python lists.\u001b[39;00m\n\u001b[0;32m   3597\u001b[0m \n\u001b[0;32m   3598\u001b[0m \u001b[39m    >>> df.take([-1, -2])\u001b[39;00m\n\u001b[0;32m   3599\u001b[0m \u001b[39m         name   class  max_speed\u001b[39;00m\n\u001b[0;32m   3600\u001b[0m \u001b[39m    1  monkey  mammal        NaN\u001b[39;00m\n\u001b[0;32m   3601\u001b[0m \u001b[39m    3    lion  mammal       80.5\u001b[39;00m\n\u001b[0;32m   3602\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3603\u001b[0m     \u001b[39mif\u001b[39;00m is_copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3604\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   3605\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis_copy is deprecated and will be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3606\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m'\u001b[39m\u001b[39m always returns a copy, so there is no need to specify this.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3607\u001b[0m             \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m   3608\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   3609\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\rhys-\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1153\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     yield buf\n\u001b[0;32m   1149\u001b[0m elif isinstance(buf, str):\n\u001b[0;32m   1150\u001b[0m     with open(buf, \"w\", encoding=encoding, newline=\"\") as f:\n\u001b[0;32m   1151\u001b[0m         # GH#30034 open instead of codecs.open prevents a file leak\n\u001b[0;32m   1152\u001b[0m         #  if we have an invalid encoding argument.\n\u001b[1;32m-> 1153\u001b[0m         # newline=\"\" is needed to roundtrip correctly on\n\u001b[0;32m   1154\u001b[0m         #  windows test_to_latex_filename\n\u001b[0;32m   1155\u001b[0m         yield f\n\u001b[0;32m   1156\u001b[0m else:\n",
      "File \u001b[1;32mc:\\Users\\rhys-\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m writers \u001b[39mas\u001b[39;00m libwriters\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     CompressionOptions,\n\u001b[0;32m     23\u001b[0m     FilePathOrBuffer,\n\u001b[0;32m     24\u001b[0m     FloatFormatType,\n\u001b[0;32m     25\u001b[0m     IndexLabel,\n\u001b[0;32m     26\u001b[0m     StorageOptions,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     ABCDatetimeIndex,\n\u001b[0;32m     31\u001b[0m     ABCIndex,\n\u001b[0;32m     32\u001b[0m     ABCMultiIndex,\n\u001b[0;32m     33\u001b[0m     ABCPeriodIndex,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m \u001b[39mimport\u001b[39;00m notna\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'FilePathOrBuffer' from 'pandas._typing' (c:\\Users\\rhys-\\anaconda3\\lib\\site-packages\\pandas\\_typing.py)"
     ]
    }
   ],
   "source": [
    "sub.to_csv(\"sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3004672</td>\n",
       "      <td>731.198448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id3505355</td>\n",
       "      <td>595.602127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id1217141</td>\n",
       "      <td>545.680009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2150126</td>\n",
       "      <td>999.437783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id1598245</td>\n",
       "      <td>469.483720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id0668992</td>\n",
       "      <td>786.484782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id1765014</td>\n",
       "      <td>1112.852261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id0898117</td>\n",
       "      <td>621.744437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id3905224</td>\n",
       "      <td>2251.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id1543102</td>\n",
       "      <td>566.961884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id3024712</td>\n",
       "      <td>809.723165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id3665810</td>\n",
       "      <td>507.045307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id1836461</td>\n",
       "      <td>477.312322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id3457080</td>\n",
       "      <td>734.214670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id3376065</td>\n",
       "      <td>1089.233947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id3008739</td>\n",
       "      <td>729.295115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id0902216</td>\n",
       "      <td>832.819659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id3564824</td>\n",
       "      <td>591.870828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id0820280</td>\n",
       "      <td>329.422018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id0775088</td>\n",
       "      <td>992.220300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  trip_duration\n",
       "0   id3004672     731.198448\n",
       "1   id3505355     595.602127\n",
       "2   id1217141     545.680009\n",
       "3   id2150126     999.437783\n",
       "4   id1598245     469.483720\n",
       "5   id0668992     786.484782\n",
       "6   id1765014    1112.852261\n",
       "7   id0898117     621.744437\n",
       "8   id3905224    2251.095900\n",
       "9   id1543102     566.961884\n",
       "10  id3024712     809.723165\n",
       "11  id3665810     507.045307\n",
       "12  id1836461     477.312322\n",
       "13  id3457080     734.214670\n",
       "14  id3376065    1089.233947\n",
       "15  id3008739     729.295115\n",
       "16  id0902216     832.819659\n",
       "17  id3564824     591.870828\n",
       "18  id0820280     329.422018\n",
       "19  id0775088     992.220300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test = pd.read_csv('sub.csv')\n",
    "sub_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93fc3b888e0cb9ffa465d85c091164963bd0d6f37310da138d470df672e240d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
